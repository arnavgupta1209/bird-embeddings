# Bird Embeddings with Variational Autoencoders

A PyTorch implementation of Variational Autoencoders (VAEs) for learning compressed embeddings from eBird checklist data. This project transforms high-dimensional bird species presence-absence data into meaningful low-dimensional representations that capture ecological patterns.

## ğŸ¯ Project Overview

**What it does**: Converts eBird checklists (e.g., 500+ species) into compact embeddings (e.g., 16 dimensions) that preserve ecological information.

**Why it's useful**:
- **Dimensionality reduction**: Compress large species lists into manageable vectors
- **Similarity search**: Find similar checklists based on species composition
- **Visualization**: Plot checklists in 2D/3D space
- **Feature extraction**: Use embeddings for downstream ML tasks (classification, clustering, etc.)

**Important Note**: This repository contains **code and workflows only**. Large data files and trained models are excluded due to GitHub size limits. Follow the [Getting Started](#-getting-started) section to generate them.

## ğŸ“ Project Structure

```
bird-embeddings/
â”œâ”€â”€ src/                        # âœ… Core modules (reusable code)
â”‚   â”œâ”€â”€ data/                   # Data loading and preprocessing
â”‚   â”‚   â”œâ”€â”€ loader.py          # Load eBird TSV files
â”‚   â”‚   â”œâ”€â”€ preprocessor.py    # Create species matrices
â”‚   â”‚   â”œâ”€â”€ dataset.py         # PyTorch Dataset classes
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ models/                 # VAE model architecture
â”‚   â”‚   â”œâ”€â”€ vae.py             # VariationalAutoencoder class
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ training/               # Training utilities
â”‚   â”‚   â”œâ”€â”€ trainer.py         # Training loop with noise augmentation
â”‚   â”‚   â”œâ”€â”€ utils.py           # Checkpointing, device management
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ inference/              # Embedding extraction
â”‚       â”œâ”€â”€ extractor.py       # EmbeddingExtractor class
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ data/                       # âš ï¸ NOT INCLUDED (too large)
â”‚   â”œâ”€â”€ raw/                    # Place eBird data here
â”‚   â”‚   â””â”€â”€ ebd_IN-KL_smp_relSep-2025.txt  # Download from eBird
â”‚   â””â”€â”€ processed/              # Generated embeddings (created by you)
â”‚       â””â”€â”€ kerala_embeddings.npz
â”‚
â”œâ”€â”€ models/                     # âš ï¸ NOT INCLUDED (too large)
â”‚   â””â”€â”€ vae_kerala.pth         # Trained models (created by you)
â”‚
â”œâ”€â”€ checkpoints/                # Training checkpoints (created during training)
â”‚
â”œâ”€â”€ scripts/                    # âœ… Utility scripts
â”‚   â”œâ”€â”€ train_new_model.py     # Train and save compatible models
â”‚   â”œâ”€â”€ check_model_compatibility.py  # Verify model format
â”‚   â””â”€â”€ test_extractor_fix.py  # Quick inference test
â”‚
â”œâ”€â”€ notebooks/                  # âœ… Training notebooks
â”‚   â””â”€â”€ train_vae_kerala.ipynb # Example training workflow
â”‚
â”œâ”€â”€ test_notebooks/             # âœ… Test suite
â”‚   â”œâ”€â”€ test_vae_module.ipynb
â”‚   â”œâ”€â”€ test_data_pipeline.ipynb
â”‚   â”œâ”€â”€ test_training.ipynb
â”‚   â””â”€â”€ test_inference.ipynb
â”‚
â”œâ”€â”€ projects/                   # âœ… Example downstream tasks
â”‚   â”œâ”€â”€ district_prediction/   # Predict district from embeddings
â”‚   â”œâ”€â”€ wetland_prediction/    # Classify wetland habitats
â”‚   â””â”€â”€ _template/             # Project template for new analyses
â”‚
â”œâ”€â”€ docs/                       # âœ… Documentation
â”‚   â”œâ”€â”€ INFERENCE_FIX_SUMMARY.md
â”‚   â”œâ”€â”€ TEST_INFERENCE_READY.md
â”‚   â”œâ”€â”€ ORGANIZATION_SUMMARY.md
â”‚   â””â”€â”€ PHASE_2_SUMMARY.md
â”‚
â”œâ”€â”€ requirements.txt            # âœ… Python dependencies
â”œâ”€â”€ .gitignore                  # âœ… Ignore large files and old notebooks
â””â”€â”€ README.md                   # This file
```

**Legend:**
- âœ… Included in repository
- âš ï¸ Not included (generate yourself following the workflow)


## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- PyTorch
- Pandas, NumPy, scikit-learn
- Jupyter Notebook (for interactive analysis)

### Installation

1. Clone repository: `git clone <repository-url>`
2. Install dependencies: `pip install -r requirements.txt`

### Data Setup

**Required:** Download Kerala eBird data from [eBird](https://ebird.org/data/download)

1. Request eBird Basic Dataset (EBD) for **Kerala, India** (region code: `IN-KL`)
2. Download the sampling event file: `ebd_IN-KL_smp_relSep-2025.txt` (or latest)
3. Place the file in `data/raw/ebd_IN-KL_smp_relSep-2025.txt`

**Note:** The actual data and trained models are NOT included in this repository due to size constraints. You need to generate them following the workflow below.

---

## ğŸ“‹ Complete Workflow

### Step 1: Train the VAE Model

**Option A - Use training script (recommended):**
```bash
python scripts/train_new_model.py
```

**Option B - Use training notebook:**
- Open and run `notebooks/train_vae_kerala.ipynb`
- Follow the cells to load data, create species matrix, and train model
- Model will be saved to `models/` directory

**What this does:**
- Loads eBird data from `data/raw/`
- Creates species presence-absence matrix
- Trains VAE model (50 epochs, ~30 min on GPU)
- Saves trained model for inference

### Step 2: Extract Embeddings

**Run inference notebook:**
- Open `test_notebooks/test_inference.ipynb`
- Load your trained model
- Extract embeddings from checklists
- Save embeddings to `data/processed/`

### Step 3: Use Embeddings for Downstream Tasks

**Example projects in `projects/` folder:**

- **District Prediction:** `projects/district_prediction/`
  - Run notebooks 01 â†’ 02 â†’ 03 in order
  - Predicts Kerala district from embeddings
  
- **Wetland Classification:** `projects/wetland_prediction/`
  - Run preprocessing notebooks (00, 00b)
  - Then run 01 â†’ 02 for analysis
  - Classifies wetland vs non-wetland habitats

---

## ğŸ§ª Testing & Validation

### Quick Test

Verify everything is working:

```bash
python scripts/test_extractor_fix.py
```

### Run Test Notebooks

Test individual components:
- `test_notebooks/test_data_pipeline.ipynb` - Data loading
- `test_notebooks/test_training.ipynb` - Training pipeline
- `test_notebooks/test_inference.ipynb` - Embedding extraction
- `test_notebooks/test_vae_module.ipynb` - VAE model

### Check Model Compatibility

```bash
python scripts/check_model_compatibility.py models/vae_kerala.pth
```

## ğŸ“Š Data Format

**Input**: eBird checklist data in TSV format
- Columns include species observations, location, date, etc.
- Each row represents a single species observation in a checklist

**Preprocessed**: Binary/one-hot encoded species presence-absence matrix
- Rows = checklists
- Columns = species
- Values = 0 (absent) or 1 (present)

**Output**: Continuous embeddings
- Each checklist â†’ 16-dimensional vector (configurable)

## ğŸ§  Model Architecture

```
Input: [batch_size, num_species] (e.g., [32, 500])
    â†“
Encoder: 3-layer MLP (500 â†’ 512 â†’ 512 â†’ 512)
    â†“
Latent Parameters: Î¼ and log(ÏƒÂ²) (each [batch_size, 16])
    â†“
Reparameterization: z = Î¼ + Ïƒ * Îµ, where Îµ ~ N(0,1)
    â†“
Decoder: 3-layer MLP (16 â†’ 512 â†’ 512 â†’ 512 â†’ 500)
    â†“
Output: [batch_size, num_species] (reconstructed, sigmoid)
```

**Loss Function**:
```
Total Loss = BCE(reconstruction, input) + KL(N(Î¼, ÏƒÂ²) || N(0, 1))
```

- **Reconstruction Loss**: Binary cross-entropy between input and reconstruction
- **KL Divergence**: Regularizes latent space to follow standard normal distribution

## ğŸ“ˆ Current Status

### âœ… Complete Modules

**Phase 1-5: Core Infrastructure - COMPLETE**
- âœ… Project structure and organization
- âœ… VAE model architecture (`src/models/`)
- âœ… Data loading and preprocessing (`src/data/`)
- âœ… Training pipeline with noise augmentation (`src/training/`)
- âœ… Inference and embedding extraction (`src/inference/`)
- âœ… All test notebooks passing
- âœ… Utility scripts for training and testing
- âœ… Comprehensive documentation

**Example Projects - COMPLETE**
- âœ… District prediction (Random Forest + Neural Network)
- âœ… Wetland habitat classification (three approaches)

### ğŸ¯ What You Can Do

With this repository, you can:

1. **Train VAE models** on your own eBird data
2. **Extract embeddings** from bird checklists
3. **Use embeddings** for downstream ML tasks:
   - Geographic prediction (district, region)
   - Habitat classification (wetland, forest, etc.)
   - Species distribution modeling
   - Checklist similarity search
   - Clustering analysis

### âš ï¸ What's NOT Included

Due to GitHub file size limits:
- âŒ Raw eBird data files (download from eBird.org)
- âŒ Trained model checkpoints (generate using workflow)
- âŒ Processed embeddings (extract using inference module)
- âŒ Old/legacy notebooks (analysis.ipynb, main.ipynb)

### ğŸ”„ Repository Philosophy

This repository provides **code and workflows**, not data or pre-trained models. 

**Why?** 
- eBird data files are multi-GB in size
- Models are specific to your dataset
- Following the workflow teaches you the full pipeline
- You maintain control over data quality and preprocessing choices

## ğŸ”§ Development

### Test Notebooks
All test notebooks are passing:
- `test_notebooks/test_vae_module.ipynb` - Tests VAE model architecture
- `test_notebooks/test_data_pipeline.ipynb` - Tests data loading and preprocessing
- `test_notebooks/test_training.ipynb` - Tests training pipeline
- `test_notebooks/test_inference.ipynb` - Tests embedding extraction

### Training Notebooks
- `notebooks/train_vae_kerala.ipynb` - Example VAE training workflow

### Utility Scripts
Run from project root:
- `python scripts/train_new_model.py` - Train new VAE model
- `python scripts/check_model_compatibility.py` - Verify model format
- `python scripts/test_extractor_fix.py` - Quick inference test

### Model Compatibility

âš ï¸ **Important**: Always save models using `save_model_for_inference()` to ensure compatibility with the inference module. See `src/training/README.md` for details.

## ğŸ“ Documentation

- **Main README** (this file): Project overview and quick start
- **Module READMEs**: Detailed docs in each `src/` subdirectory
  - `src/models/README.md` - VAE architecture details
  - `src/data/README.md` - Data pipeline documentation  
  - `src/training/README.md` - Training utilities
  - `src/inference/README.md` - Embedding extraction guide
- **Fix Documentation**: `docs/` folder
  - `INFERENCE_FIX_SUMMARY.md` - Technical details of the inference fix
  - `TEST_INFERENCE_READY.md` - How to use test_inference.ipynb
  - `PHASE_2_SUMMARY.md` - Phase 2 development summary
  - `ORGANIZATION_SUMMARY.md` - Project organization details

## â“ FAQ & Troubleshooting

### Where is the data and models?

**Not included** due to GitHub size limits. Follow these steps:

1. Download eBird data from https://ebird.org/data/download
2. Run the complete workflow in [Getting Started](#-getting-started) to:
   - Create species matrices
   - Train your VAE model
   - Extract embeddings

### What eBird data file do I need?

Request the **eBird Basic Dataset (EBD)** for your region of interest. For Kerala, India:
- Region code: `IN-KL`
- File format: Sampling event data (TSV)
- Example: `ebd_IN-KL_smp_relSep-2025.txt`



### Model is too large / running out of memory?

Options to reduce memory usage:
- Reduce `latent_dimension` from 16 to 8
- Reduce `hidden_dimension` from 512 to 256
- Increase `min_species_observations` to filter more species
- Use smaller batch size

See module READMEs in `src/` for detailed parameter tuning.

### How do I choose hyperparameters?

**Start with defaults**, then tune:
- `latent_dimension`: 8-32 (smaller = more compression)
- `hidden_dimension`: 256-512 (larger = more capacity)
- `noise_std`: 0.05-0.2 (higher = more regularization)
- `learning_rate`: 1e-4 to 1e-3

See `src/training/README.md` for comprehensive hyperparameter guide.

### Inference module not loading my model?

Make sure you saved the model using `save_model_for_inference()` from `src.training`. Don't use `torch.save(model, ...)` directly. See `src/training/README.md` for proper model saving.

## ğŸ“š References

- **Kingma & Welling (2013)**: "Auto-Encoding Variational Bayes" - Original VAE paper
- **Doersch (2016)**: "Tutorial on Variational Autoencoders" - Excellent introduction
- **eBird**: https://ebird.org/ - Bird observation data source

---

## ğŸ—‚ï¸ Example Projects

### District Prediction

Predict Kerala district from bird checklist embeddings using Random Forest classifier.

**Location:** `projects/district_prediction/`

**Goal:** Train a classifier to predict which of 14 Kerala districts a checklist comes from using only the 16-dimensional embedding.

**Key Results:** ~70-80% accuracy on district prediction

**Workflow:**
1. `01_exploration.ipynb` - Load data, extract embeddings, add district labels
2. `02_analysis.ipynb` - Train Random Forest classifier
3. `02b_neural_network.ipynb` - Train neural network classifier
4. `03_results.ipynb` - Visualize confusion matrix, feature importance

---

### Wetland Habitat Classification

Predict whether a checklist location is near wetland habitat using species composition embeddings.

**Location:** `projects/wetland_prediction/`

**Goal:** Determine if VAE embeddings capture habitat information using three labeling approaches:

1. **Bird Proportion Heuristic:** Label based on % of wetland-indicator species (94.6% accuracy)
2. **Hotspot Name Heuristic:** Label based on location name keywords (87.9% accuracy)
3. **Intersection Approach:** Combine both heuristics for stricter labels (97.0% accuracy)

**Key Insight:** High accuracy on hotspot-based labels (independent of species data) proves embeddings learned meaningful habitat associations.

**Workflow:**
1. `00_preprocessing_proportion_heuristic.ipynb` - Create bird-based labels
2. `00b_preprocessing_hotspot_heuristic.ipynb` - Create location-based labels
3. `01_exploration.ipynb` - Load embeddings and labels
4. `02_analysis.ipynb` - Train classifiers and compare approaches

---

**Last Updated**: January 8, 2026  
**Status**: âœ… Core modules complete, tested, and documented  
**Note**: Data and models not included - generate using provided workflows
