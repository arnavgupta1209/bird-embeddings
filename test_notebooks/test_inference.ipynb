{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Inference Module\n",
    "This notebook tests the inference module for extracting embeddings from eBird checklists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.inference import EmbeddingExtractor, load_and_extract, save_embeddings, load_embeddings\n",
    "from src.data.loader import load_ebird_data\n",
    "from src.data.preprocessor import EBirdPreprocessor\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('✓ Imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "✓ Loaded eBird data from: ebd_IN-KL_smp_relSep-2025.txt\n",
      "  Rows: 50,000\n",
      "  Columns: 53\n",
      "  (Limited to first 50,000 rows)\n",
      "\n",
      "Preprocessing...\n",
      "Input data: 50,000 observations\n",
      "  Unique checklists: 2,982\n",
      "  Unique species: 549\n",
      "\n",
      "Applying quality filters...\n",
      "  After CATEGORY='species': 46,839 observations (3,161 removed)\n",
      "  After OBSERVATION TYPE filter: 32,899 observations (13,940 removed)\n",
      "  After ALL SPECIES REPORTED=1: 24,912 observations (7,987 removed)\n",
      "\n",
      "✓ Quality filters applied: 50,000 → 24,912 observations\n",
      "  Removed: 25,088 (50.2%)\n",
      "\n",
      "Filtered data:\n",
      "  Unique checklists: 1,102\n",
      "  Unique species: 373\n",
      "\n",
      "Pivoting data to create species matrix...\n",
      "✓ Initial matrix: 1,102 checklists × 373 species\n",
      "\n",
      "✓ Final matrix: 1,102 checklists × 373 species\n",
      "\n",
      "✓ Loaded and processed 1102 checklists\n",
      "  Feature dimensions: 373\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess sample data\n",
    "data_path = r'C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\data\\raw\\ebd_IN-KL_smp_relSep-2025.txt'\n",
    "\n",
    "print('Loading data...')\n",
    "df = load_ebird_data(data_path, nrows=50000)\n",
    "\n",
    "print('\\nPreprocessing...')\n",
    "preprocessor = EBirdPreprocessor()\n",
    "processed_df = preprocessor.fit_transform(df)\n",
    "\n",
    "print(f'\\n✓ Loaded and processed {len(processed_df)} checklists')\n",
    "print(f'  Feature dimensions: {processed_df.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test EmbeddingExtractor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing extractor...\n",
      "✓ Model loaded from C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\vae_model_inference_ready.pth\n",
      "  Input dim: 373, Latent dim: 16, Hidden dim: 512, Device: cpu\n",
      "\n",
      "✓ Extractor initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize extractor with trained model\n",
    "# Use the new model trained with save_model_for_inference()\n",
    "model_path = r'C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\models\\vae_model_inference_ready.pth'\n",
    "\n",
    "print('Initializing extractor...')\n",
    "extractor = EmbeddingExtractor(model_path, device='cpu')\n",
    "\n",
    "print('\\n✓ Extractor initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Embeddings (Deterministic Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (deterministic mode)...\n",
      "\n",
      "✓ Extracted embeddings\n",
      "  Shape: (1102, 16)\n",
      "  Min: -0.1648\n",
      "  Max: 0.0998\n",
      "  Mean: -0.0015\n",
      "  Std: 0.0266\n"
     ]
    }
   ],
   "source": [
    "# Extract using mean only (deterministic)\n",
    "print('Extracting embeddings (deterministic mode)...')\n",
    "embeddings_mean = extractor.extract_embeddings(processed_df, use_mean=True, batch_size=128)\n",
    "\n",
    "print(f'\\n✓ Extracted embeddings')\n",
    "print(f'  Shape: {embeddings_mean.shape}')\n",
    "print(f'  Min: {embeddings_mean.min():.4f}')\n",
    "print(f'  Max: {embeddings_mean.max():.4f}')\n",
    "print(f'  Mean: {embeddings_mean.mean():.4f}')\n",
    "print(f'  Std: {embeddings_mean.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Embeddings (Stochastic Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (stochastic mode)...\n",
      "\n",
      "✓ Extracted embeddings\n",
      "  Shape: (1102, 16)\n",
      "  Min: -3.8627\n",
      "  Max: 3.7742\n",
      "  Mean: 0.0007\n",
      "  Std: 1.0174\n"
     ]
    }
   ],
   "source": [
    "# Extract by sampling (stochastic)\n",
    "print('Extracting embeddings (stochastic mode)...')\n",
    "embeddings_sample = extractor.extract_embeddings(processed_df, use_mean=False, batch_size=128)\n",
    "\n",
    "print(f'\\n✓ Extracted embeddings')\n",
    "print(f'  Shape: {embeddings_sample.shape}')\n",
    "print(f'  Min: {embeddings_sample.min():.4f}')\n",
    "print(f'  Max: {embeddings_sample.max():.4f}')\n",
    "print(f'  Mean: {embeddings_sample.mean():.4f}')\n",
    "print(f'  Std: {embeddings_sample.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Deterministic vs Stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between deterministic and stochastic modes:\n",
      "  Mean absolute difference: 0.8103\n",
      "  Max absolute difference: 3.8697\n",
      "\n",
      "Note: Some difference is expected due to sampling in stochastic mode\n"
     ]
    }
   ],
   "source": [
    "# Compare the two modes\n",
    "diff = np.abs(embeddings_mean - embeddings_sample)\n",
    "\n",
    "print('Difference between deterministic and stochastic modes:')\n",
    "print(f'  Mean absolute difference: {diff.mean():.4f}')\n",
    "print(f'  Max absolute difference: {diff.max():.4f}')\n",
    "print(f'\\nNote: Some difference is expected due to sampling in stochastic mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Extract with Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings with reconstructions...\n",
      "\n",
      "✓ Extracted embeddings and reconstructions\n",
      "  Embeddings shape: (10, 16)\n",
      "  Reconstructions shape: (10, 373)\n",
      "  Mean reconstruction error (MSE): 0.100942\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings and reconstructions\n",
    "print('Extracting embeddings with reconstructions...')\n",
    "embeddings, reconstructions = extractor.extract_with_reconstruction(\n",
    "    processed_df.iloc[:10],  # Just test on 10 samples\n",
    "    use_mean=True\n",
    ")\n",
    "\n",
    "print(f'\\n✓ Extracted embeddings and reconstructions')\n",
    "print(f'  Embeddings shape: {embeddings.shape}')\n",
    "print(f'  Reconstructions shape: {reconstructions.shape}')\n",
    "\n",
    "# Compute reconstruction error\n",
    "original = processed_df.iloc[:10].values\n",
    "recon_error = np.mean((original - reconstructions) ** 2)\n",
    "print(f'  Mean reconstruction error (MSE): {recon_error:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Convenience Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing load_and_extract convenience function...\n",
      "✓ Model loaded from C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\vae_model_inference_ready.pth\n",
      "  Input dim: 373, Latent dim: 16, Hidden dim: 512, Device: cpu\n",
      "\n",
      "✓ Quick extraction successful\n",
      "  Shape: (10, 16)\n",
      "  ✓ Results match extractor (max diff: 0.00e+00)\n"
     ]
    }
   ],
   "source": [
    "# Test load_and_extract convenience function\n",
    "print('Testing load_and_extract convenience function...')\n",
    "embeddings_quick = load_and_extract(\n",
    "    model_path=model_path,\n",
    "    data=processed_df.iloc[:10],\n",
    "    use_mean=True,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(f'\\n✓ Quick extraction successful')\n",
    "print(f'  Shape: {embeddings_quick.shape}')\n",
    "\n",
    "# Verify it matches the extractor result\n",
    "max_diff = np.abs(embeddings_quick - embeddings).max()\n",
    "if max_diff < 1e-6:\n",
    "    print(f'  ✓ Results match extractor (max diff: {max_diff:.2e})')\n",
    "else:\n",
    "    print(f'  ✗ Results differ (max diff: {max_diff:.2e})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Save/Load Embeddings (NPZ format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to NPZ...\n",
      "✓ Embeddings saved to C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.npz\n",
      "\n",
      "Loading embeddings from NPZ...\n",
      "\n",
      "✓ Loaded embeddings\n",
      "  Shape: (1102, 16)\n",
      "  IDs shape: (1102,)\n",
      "  ✓ Embeddings match original\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings as NPZ\n",
    "save_path_npz = r'C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.npz'\n",
    "checklist_ids = pd.Series(range(len(embeddings_mean)))\n",
    "\n",
    "print('Saving embeddings to NPZ...')\n",
    "save_embeddings(\n",
    "    embeddings_mean,\n",
    "    save_path_npz,\n",
    "    checklist_ids=checklist_ids,\n",
    "    metadata={'model': 'vae_kerala', 'latent_dim': embeddings_mean.shape[1]}\n",
    ")\n",
    "\n",
    "# Load back\n",
    "print('\\nLoading embeddings from NPZ...')\n",
    "loaded_embeddings, loaded_ids = load_embeddings(save_path_npz)\n",
    "\n",
    "print(f'\\n✓ Loaded embeddings')\n",
    "print(f'  Shape: {loaded_embeddings.shape}')\n",
    "print(f'  IDs shape: {loaded_ids.shape}')\n",
    "\n",
    "# Verify\n",
    "if np.allclose(loaded_embeddings, embeddings_mean):\n",
    "    print('  ✓ Embeddings match original')\n",
    "else:\n",
    "    print('  ✗ Embeddings differ from original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Save/Load Embeddings (CSV format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to CSV...\n",
      "✓ Embeddings saved to C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.csv\n",
      "\n",
      "Loading embeddings from CSV...\n",
      "\n",
      "✓ Loaded embeddings\n",
      "  Shape: (10, 16)\n",
      "  ✓ Embeddings match original\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings as CSV\n",
    "save_path_csv = r'C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.csv'\n",
    "\n",
    "print('Saving embeddings to CSV...')\n",
    "save_embeddings(\n",
    "    embeddings_mean[:10],  # Just save first 10 for CSV\n",
    "    save_path_csv,\n",
    "    checklist_ids=checklist_ids[:10]\n",
    ")\n",
    "\n",
    "# Load back\n",
    "print('\\nLoading embeddings from CSV...')\n",
    "loaded_csv = load_embeddings(save_path_csv)\n",
    "\n",
    "print(f'\\n✓ Loaded embeddings')\n",
    "print(f'  Shape: {loaded_csv.shape}')\n",
    "\n",
    "# Verify\n",
    "if np.allclose(loaded_csv, embeddings_mean[:10]):\n",
    "    print('  ✓ Embeddings match original')\n",
    "else:\n",
    "    print('  ✗ Embeddings differ from original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Different Input Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataFrame input...\n",
      "  ✓ DataFrame: (5, 16)\n",
      "Testing Numpy array input...\n",
      "  ✓ Numpy array: (5, 16)\n",
      "Testing Tensor input...\n",
      "  ✓ Tensor: (5, 16)\n",
      "\n",
      "✓ All input types produce identical results\n"
     ]
    }
   ],
   "source": [
    "# Test with different input formats\n",
    "sample_data = processed_df.iloc[:5]\n",
    "\n",
    "# 1. DataFrame input\n",
    "print('Testing DataFrame input...')\n",
    "emb_df = extractor.extract_embeddings(sample_data, use_mean=True)\n",
    "print(f'  ✓ DataFrame: {emb_df.shape}')\n",
    "\n",
    "# 2. Numpy array input\n",
    "print('Testing Numpy array input...')\n",
    "emb_np = extractor.extract_embeddings(sample_data.values, use_mean=True)\n",
    "print(f'  ✓ Numpy array: {emb_np.shape}')\n",
    "\n",
    "# 3. Tensor input\n",
    "print('Testing Tensor input...')\n",
    "emb_tensor = extractor.extract_embeddings(torch.FloatTensor(sample_data.values), use_mean=True)\n",
    "print(f'  ✓ Tensor: {emb_tensor.shape}')\n",
    "\n",
    "# Verify all produce same results\n",
    "if np.allclose(emb_df, emb_np) and np.allclose(emb_np, emb_tensor):\n",
    "    print('\\n✓ All input types produce identical results')\n",
    "else:\n",
    "    print('\\n✗ Input types produce different results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.npz\n",
      "Removed C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.csv\n",
      "\n",
      "✓ All tests completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Remove test files\n",
    "for file in [r'C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.npz', r'C:\\Users\\Arnav\\Documents\\Python Scripts\\bird embeddings\\embeddings_test.csv']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f'Removed {file}')\n",
    "\n",
    "print('\\n✓ All tests completed successfully!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
