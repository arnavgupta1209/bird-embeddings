{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Exploration\n",
    "\n",
    "Initial data exploration and setup.\n",
    "\n",
    "**Tasks:**\n",
    "- Load and explore eBird data\n",
    "- Preprocess data\n",
    "- Extract embeddings\n",
    "- Add project-specific labels/features\n",
    "- Save processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add backbone to path\n",
    "project_root = Path.cwd().parent.parent  # Go up to bird-embeddings/\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current project: {Path.cwd().parent.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load eBird Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import load_ebird_data\n",
    "\n",
    "# Load shared eBird data\n",
    "data_path = project_root / 'data' / 'raw' / 'ebd_IN-KL_smp_relSep-2025.txt'\n",
    "df = load_ebird_data(str(data_path), nrows=50000)  # Adjust nrows as needed\n",
    "\n",
    "print(f\"Loaded {len(df)} observations\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your exploration code here\n",
    "# Example:\n",
    "print(f\"Unique checklists: {df['SAMPLING EVENT IDENTIFIER'].nunique()}\")\n",
    "print(f\"Unique species: {df['COMMON NAME'].nunique()}\")\n",
    "print(f\"Date range: {df['OBSERVATION DATE'].min()} to {df['OBSERVATION DATE'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import EBirdPreprocessor\n",
    "\n",
    "# Preprocess using backbone\n",
    "preprocessor = EBirdPreprocessor()\n",
    "processed_df = preprocessor.fit_transform(df)\n",
    "\n",
    "print(f\"Processed shape: {processed_df.shape}\")\n",
    "print(f\"Features (species): {processed_df.shape[1]}\")\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import EmbeddingExtractor\n",
    "\n",
    "# Load shared VAE model\n",
    "model_path = project_root / 'models' / 'vae_model_inference_ready.pth'\n",
    "extractor = EmbeddingExtractor(str(model_path), device='cpu')\n",
    "\n",
    "# Extract embeddings\n",
    "embeddings = extractor.extract_embeddings(processed_df, use_mean=True)\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Latent dimensions: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Project-Specific Features/Labels\n",
    "\n",
    "**TODO**: Add your project-specific code here.\n",
    "\n",
    "Examples:\n",
    "- Extract labels from location/date/other columns\n",
    "- Compute additional features\n",
    "- Filter data for specific analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Add labels\n",
    "# labels = df.loc[processed_df.index, 'YOUR_LABEL_COLUMN']\n",
    "\n",
    "# Your code here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings and metadata to project folder\n",
    "save_path = Path('../data/processed/embeddings.npz')\n",
    "\n",
    "np.savez(\n",
    "    save_path,\n",
    "    embeddings=embeddings,\n",
    "    # Add your labels/metadata here\n",
    "    # labels=labels.values,\n",
    "    checklist_ids=processed_df.index.values\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Saved processed data to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**TODO**: Summarize what you found in this exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
